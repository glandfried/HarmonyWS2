---
title: Session 7
subtitle: Incorporating imperfect sensitivity and specificity into more complex models
date: "2021-07-01"
author:
  - Matt Denwood
theme: metropolis
aspectratio: 43
colortheme: seahorse
header-includes: 
  - \input{../rsc/preamble}
params:
  presentation: TRUE
output:
  beamer_presentation:
      pandoc_args: ["-t", "beamer"]
      slide_level: 2
  html_document: default
---

```{r rendering, eval=FALSE, include=FALSE}
# To render this as PDF (beamer) slides run:
rmarkdown::render('Session_7.Rmd', 'beamer_presentation', params=list(presentation=TRUE))
# And for html:
rmarkdown::render('Session_7.Rmd', 'html_document', params=list(presentation=FALSE))
```

```{r setup, include=FALSE}
source("../rsc/setup.R")
```

## Recap

Models for diagnostic test evaluation require:

  - At least 2 tests
  - At least 2 populations, but preferably 3 or more
  - Quite a lot of data

. . .

Fitting the models is technically quite straightforward

The real difficulty lies in the interpretation

  - What exactly is the latent class?


# Incorporating imperfect sensitivity and specificity into more complex models

## Logistic regression in JAGS

```{r echo=FALSE, comment=""}
lrmod <- "model{

  for(i in 1:N){
    Outcome[i] ~ dbern(prob[i])
    logit(prob[i]) <- intercept + beta1[Category[i]] + beta2*Covariate[i]
  }

  intercept ~ dnorm(0, 10^-6)
  beta1 ~ dnorm(0, 10^-6)
  beta2 ~ dnorm(0, 10^-6)

  #data# N, Outcome, Category, Covariate
  #monitor# intercept, beta1, beta2
  #inits# intercept, beta1, beta2
}"
cat(lrmod)
cat(lrmod, file="logistic_imperfect.txt")
cleanup <- c(cleanup, "logistic_imperfect.txt")
```

- - -


```{r echo=FALSE, comment=""}
lrmod <- "model{

  for(i in 1:N){
    Outcome[i] ~ dbern(obs_prob[i])
    obs_prob[i] <- prob[i]*se + (1-prob[i])*(1-sp)
    logit(prob[i]) <- intercept + beta1[Category[i]] + beta2*Covariate[i]
  }

  se ~ dbeta(1,1)T(1-sp, )
  sp ~ dbeta(1,1)

  intercept ~ dnorm(0, 10^-6)
  beta1 ~ dnorm(0, 10^-6)
  beta2 ~ dnorm(0, 10^-6)

  #data# N, Outcome, Category, Covariate
  #monitor# intercept, beta1, beta2, se, sp
  #inits# intercept, beta1, beta2, se, sp
}"
cat(lrmod)
cat(lrmod, file="logistic_imperfect.txt")
```

- - -


```{r echo=FALSE, comment=""}
lrmod <- "model{

  for(i in 1:N){
    Outcome[i] ~ dbern(obs_prob[i])
    obs_prob[i] <- prob[i]*se + (1-prob[i])*(1-sp)
    logit(prob[i]) <- intercept + beta1[Category[i]] + beta2*Covariate[i]
  }

  se ~ dbeta(148.43, 16.49)T(1-sp, )
  sp ~ dbeta(240.03, 12.63)

  intercept ~ dnorm(0, 10^-6)
  beta1 ~ dnorm(0, 10^-6)
  beta2 ~ dnorm(0, 10^-6)

  #data# N, Outcome, Category, Covariate
  #monitor# intercept, beta1, beta2, se, sp
  #inits# intercept, beta1, beta2, se, sp
}"
cat(lrmod)
cat(lrmod, file="logistic_imperfect.txt")
```

- - -


```{r echo=FALSE, comment=""}
lrmod <- "model{

  for(i in 1:N){
    Outcome[i] ~ dbern(obs_prob[i])
    obs_prob[i] <- prob[i]*se[Test[i]] + (1-prob[i])*(1-sp[Test[i]])
    logit(prob[i]) <- intercept + beta1[Category[i]] + beta2*Covariate[i]
  }

  se[1] ~ dbeta(148.43, 16.49)T(1-sp[1], )
  sp[1] ~ dbeta(240.03, 12.63)
  se[2] ~ dbeta(183.59, 9.98)T(1-sp[2], )
  sp[2] ~ dbeta(199.22, 0.53)

  intercept ~ dnorm(0, 10^-6)
  beta1 ~ dnorm(0, 10^-6)
  beta2 ~ dnorm(0, 10^-6)

  #data# N, Outcome, Category, Covariate, Test
  #monitor# intercept, beta1, beta2, se, sp
  #inits# intercept, beta1, beta2, se, sp
}"
cat(lrmod)
cat(lrmod, file="logistic_imperfect.txt")
```

## Other types of GL(M)M

You can use template.jags as inspiration:

```{r echo=FALSE}
ctl <- c(4.17,5.58,5.18,6.11,4.50,4.61,5.17,4.53,5.33,5.14)
trt <- c(4.81,4.17,4.41,3.59,5.87,3.83,6.03,4.89,4.32,4.69)
group <- gl(2, 10, 20, labels = c("Ctl","Trt"))
weight <- c(ctl, trt)
data <- data.frame(weight, group)
cleanup <- c(cleanup, "linear_model.txt")
```


```{r}
template.jags(weight ~ group, family="gaussian", data=data, file="linear_model.txt")
results <- run.jags("linear_model.txt")
```

- - -

```{r}
results
```

- - -

Supported features:

  - Gaussian, binomial, Poisson, negative binomial, ZIB, ZIP, ZINB
  - Random intercepts

We can also add (currently manually):

  - Random slopes
  - Spline terms
  - Interval censoring


## What about other models?

MCMC is highly flexible!

. . . 

We can have:

  - Hidden Markov models
  - State Space models
  - Other types of latent class model

. . .

But does your data match your ambitions?

  - All models can be specified
  - Relatively few are identifiable

## Before you go...

- Feedback on the course would be extremely welcome!
  - I will send an email later today with a survey link

. . .

- Remember to keep an eye on the COST action website:
  - http://harmony-net.eu
  - Physical training schools are being run in September and accepting sign-ups now!


# Practical session 7

## Points to consider {.fragile}

1. When is there a benefit of adding imperfect test information?

2. When is there no real benefit?


`r exercise_start()`

## Exercise 1

Use the dataset provided
  
  - Only intercept is affected when test is consistent
  - If test is inconsistent then we have problems
  - Bigger problems when the test is confounded with predictor


## Optional exercises

Re-visit the exercises (and optional exercises) from sessions 3-4 that you did not finish!


`r exercise_end()`


```{r include=FALSE}
unlink(cleanup)
```
